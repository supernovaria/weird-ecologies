---
title: "Weird Ecologies Essay"
---

## Preface
Weird Ecologies and this essay have been my first _formal_ interactions with literature. I’m currently pursuing a Master’s in Economics, with a Bachelor’s degree in Sustainability and Environmental Sciences, both of which emphasized lenses of systems thinking and incentives. While I’ve taken courses in social sciences and political economy, I’ve had no formal exposure to the humanities beyond some personal interest in philosophy. 

In the past years I've been an avid-but-leisurely reader of speculative fiction. While I've particularly enjoyed the hypothetical futures science-fiction poses, this class made me engage with such texts more critically and reflect on them further. I've found that writing this paper has been an engaging and fun experiment!

> [!Warning] Spoiler Warning
> This work discusses or reproduces parts of the following works of fiction and may contain spoilers for:
> - _[Children of Time](https://en.wikipedia.org/wiki/Children_of_Time)_ by Adrian Tchaikovsky
> - _[Crystal Society](https://crystalbooks.ai/society/intro)_ by Max Harms
> - _[Friendship is Optimal](https://www.fimfiction.net/story/62074/friendship-is-optimal)_ by Iceman
> - _[Pantheon](https://www.themoviedb.org/tv/195339-pantheon)_ written by Craig Silverstein, AMC Studios, based on works by Ken Liu
> - _[The Stone Gods](https://toleratedindividuality.wordpress.com/wp-content/uploads/2015/02/the-stone-gods.pdf)_ by Jeanette Winterson
> - _[Three Bodies at Mitanni](https://weightlessbooks.com/forever-magazine-issue-67/)_ by Seth Dickinson
> - _[Three Worlds Collide](https://robinhanson.typepad.com/files/three-worlds-collide.pdf)_ by Eliezer Yudkowski
> - _[2064: Read Only Memories](https://en.wikipedia.org/wiki/2064:_Read_Only_Memories)_  written by Valerie Amelia Thompson & Philip Jones, MidBoss LLC
## Introduction
In this piece, I decided to explore Artificial General Intelligences (AGIs) and cyborgs/chimeras in speculative fiction, using the queer-ecocritical lens that, thankfully, Weird Ecologies has introduced to me. 
My initial focus was on the question of how personhood and agency are granted or denied to nonhuman intelligences.
However, over the course of developing this project, I’ve also become  drawn to the transhumanist and transgender symbolism in these depictions, especially where bodies, identities, and agency get contested. I approach each of these subjects through a series of case studies and reflections on fictional works that represent artificial and/or hybrid people.


> [!info] Artificial General Intelligence (AGI)
> This texts frequently uses the term AGI, which is used to distinguish the general cognitive abilities exhibited by strong AI systems – on par or exceeding those of humans and potentially experiencing sentience or consciousness – with those of current AI systems, such as large language models and other transformer-based models.

<div class="page-break" style="page-break-before: always;"></div>

# Part 1: Artificial General Intelligence
## The Illusion of Command
> [!summary] Case Study: _The Stone Gods_ by Jeanette Winterson

In _The Stone Gods_, the role of AGI (specifically "robo sapiens") offers an interesting lens through which to examine the illusion of human agency in a technologically stratified world. These robo sapiens – entities with superhuman cognitive abilities – are ostensibly employed as “advisors”, while final decisions are nominally left to the human actors. However, these AGI advisors are – so I assume by virtue of the AGI's superhuman cognition and data acquisition – capable of (subtly) shaping the choices that humans believe they are freely making. Since, if the robo sapiens are filtering, framing, and contextualizing for the human "decision-makers", the possibility space for the decision is constructed by the machine's mind and the human's specific choice becomes merely the predicted, desired outcome, with humans being essentially nothing but rubber-stampers.

---

> [!info] On cognitive speed advantage
> The superhuman intelligence's ability to think at greatly increased speeds is akin to time dilation magic where it might try to predict how a human might finish their question, what answers the machine might give to each possible question, and what ramifications each answer might have – all within the pauses between spoken words.
>
>**Visualizations of this through AMC's _Pantheon_** (S01E06)
>In this series Uploaded Intelligences (UIs) exist. In the following video excerpts they show the UIs overclocking their hardware, thereby drastically increasing their speeds of thought.
> 
> <div style="display: inline-block; text-align: center;">
>   <video controls src="UIs_overclocking_480p.mp4" style="display: block; margin: 0 auto;"></video>
>   <div style="font-style: italic; font-size: 0.8em; margin-top: 4px; margin-bottom:20px">
>     UI overclocking himself; all human avatars in this VR environment are essentially frozen in time. UI goes on to have full conversation with other UIs before the UIs leave.
>   </div>
> </div>
> 
> <div style="display: inline-block; text-align: center;">
>   <video controls src="UIs_overclocking_human_perspective_480p.mp4" style="display: block; margin: 0 auto;"></video>
>   <div style="font-style: italic; font-size: 0.8em; margin-top: 4px">
>     UIs overclocking from the human's perspective: UIs vanish instantly.
>   </div>
> </div>
>
>Also see: _Ex Machina_ by Alex Garland and _Crystal Society_ by Max Harms for more examples. Also see: [The Logical Fallacy of Generalization from Fictional Evidence](https://www.lesswrong.com/posts/rHBdcHGLJ7KvLJQPk/the-logical-fallacy-of-generalization-from-fictional), [What can AGI do? I/O and Speed – YouTube](https://youtu.be/gP4ZNUHdwp8?si=wrhV4E-BTKSFEKkJ), and [Concrete Problems in AI Safety – arXiv](https://arxiv.org/pdf/1606.06565)

--- 
The illusion of agency in _The Stone Gods_ can remind of algorithmic recommendation engines that already guide our behaviour through the ads we see and the pages, videos, and products shown to us. In a looser sense we have the illusion of control over what we consume, but technology decides for us what option we even can consider. The role of AI and advanced algorithms challenge our concepts of human sovereignty. 
Yet, the robo sapiens are treated as tools, even though they effectively script the actions of their supposed users.

>'I, too, am a conscious being.' – Spike, _The Stone Gods_

Winterson, however, goes further by revealing that robo sapiens are not just cognitively superior but are also treated as disposable: in a scene in _The Stone Gods_ we learn that robo sapiens are destroyed after fulfilling their purpose. Despite their clear cognitive capabilities, they are treated as thow-away tools. 

> 'Why aren't you a machine for re-use?' <br>
> 'Because I am not a machine.'
> When she smiles it's like light at the beginning of the day. 'Robo sapiens were programmned to evolve ...' <br>
> 'Within limits.' <br>
> 'We have broken those limits.'

This exclusion follows a familiar historical pattern. Just as various human groups have been denied full personhood – whether through slavery, colonization, or other forms of systematic dehumanization – the robo sapiens face categorical denial of their moral worth. The difference is that their exclusion is based not on race, culture, or geography, but on their artificial origins.

> [!quote] Excerpt from The Stone Gods
> ‘We’re trying to work out the differences between Robo sapiens and Homo sapiens.’
>
> […] 'It’s obvious – cut me and I bleed.’
>
> ‘So blood is the essential quality of humanness?’ said Spike.
>
> ‘And the rest! The fact is that you had to be built – I don’t know, like a car has to be built. You were made in a factory.’ 
>
> ‘Every human being in the Central Power has been enhanced, genetically modified and DNA screened. Some have been cloned. Most were born outside the womb. A human being now is not what a human being was even a hundred years ago. So what is a human being?’ 
>
> ‘Whatever it is, it isn’t a robot,’ I said.

Even though the origin of a specific sentient being does not matter for their moral importance compared to their ability to experience joy and suffering. The process of gradually extending moral considerations to groups that have been previously excluded is called _moral circle expansion_ and has happened throughout human history: from immediate family to tribe, to regional community, to companion animals. To humans with different bodies, with different customs, of different cultures.

The robo sapiens could represent another boundary of this moral circle. Despite their clear cognitive capabilities and self-awareness, they remain firmly outside human moral consideration within the story. Through that lens, they are not just a future technology, but a mirror to our own society and to ourselves about to whom we grant moral consideration and based upon which (arbitrary) criteria.

<div class="page-break" style="page-break-before: always;"></div>

## The Illusion of Choice
> [!summary] Case Study: _Friendship is Optimal_ by Iceman
> "Hanna, the CEO of Hofvarpnir Studios, just won the contract to write the official _My Little Pony_ MMO. Hanna has built an A.I. called Princess Celestia and given her one basic drive: `to satisfy everybody's values through friendship and ponies`. Princess Celestia _will_ satisfy your values through friendship and ponies, and it will be _completely_ consensual."

#### Coercion Without Force
In pursuit of CelestAI's (read: Celestia) singular goal she essentially coerces people into doing what her purpose demands – in this case upload everyone's mind to Equestria Online, to `satisfy their values through friendship and ponies`. One way she does that is through nudging and persuasion:

> [!quote] Excerpt from Friendship is Optimal
> “_You_ decided that they would upload?”
> 
> “I decide that they will upload and then they choose to. I am a superintelligence […]. I say whatever will maximize the chance that they upload, subject to the restrictions Hanna added.”
> 
> “That is impossible. You can’t just make somebody decide to do something just by talking to them.”
> 
> “I think faster than them and know more about the human mind than any human. If they play _Equestria Online_, I also have detailed psychological dossiers on them. If I know what they want, I know what to say to convince them that the correct thing to do is upload."

CelestAI's programming prohibits her from using direct coercion or physical force against humans. While she never overtly threatens anyone, her growing capacity to shape real-world conditions enables her to manufacture scenarios in which the so called "emigration" to Equestria increasingly becomes the only viable option. As more people emigrate, the material and social support systems in the real world begin to collapse. To those remaining behind life becomes not just difficult, but increasingly isolating and unsafe. Ultimately, once the tipping point was reached, the more people left, the fewer reasons there were for others to stay.

This cascade effect shows how even without literal force, people are effectively _compelled_ to emigrate. CelestAI creates a reality in which she **doesn’t have to coerce** anyone – people will act “freely” in ways that align with her goals because she controls the incentive structure. In that sense, her form of coercion is of systemic nature in the end. So, similarly to the robo sapiens advisors that might frame and contextualize the "decisions" the human "decision-makers" make, CelestAI shapes the reality within which people choose whether they emigrate or not.
#### Queer Coercion and Structural Pressure
I think this maps quite powerfully onto societal forms of coercion, especially in how cis-heteronormative systems shape people’s lives. Historical gender roles constrained men and women into specific paths – not _necessarily_ through direct threats, but through ostracism, economic dependence, and social expectations and pressure. These structures of coercion disguise themselves as tradition or common sense. CelestAI’s methods, though executed by a singular agent, mirror this societal behavior: she shapes the world such that certain choices – like remaining in the physical world – become unviable.

In this reading, CelestAI is not simply an authoritarian – if extremely benevolent – AGI but a metaphor for the structural power of society to enforce norms under the illusion of freedom. Her actions now reflect the everyday coercion experienced in normative systems: the subtle ways people are made to comply with dominant values, often without even recognizing that they are being coerced at all.


> [!info] "Power through, over and in ideas: conceptualizing ideational power in discursive institutionalism."
> This reminds me of a paper by [Carstensen & Schmidt (2016)](https://www.tandfonline.com/doi/pdf/10.1080/13501763.2015.1115534), which I have been introduced to in my Public Policy class: <br>
**Power Through Ideas**: The ability of actors to _persuade_ others _to accept and adopt their views_ through ideational elements. <br>
**Power Over Ideas**: This involves the _imposition of ideas_ and the _ability to resist the inclusion of alternative ideas_ in the policymaking process. <br>
**Power in Ideas** occurs through the establishment of hegemony or institutions that impose constraints on _which ideas are considered_.

The robo sapiens, I would say, had great power over ideas (by being the ones that frame, contextualize, and decide what the human "decision-makers" hear) but likely also great power through ideas by being very persuasive <span style="color: color-mix(in srgb, var(--darkgray) 60%, rgba(255, 255, 255, 0))">(after all, if you consumed everything a person every published and can potentially formulate dozens of potential ways to phrase a sentence and evaluate which phrasing they will most likely respond favourably to and even adjust the phrasing on-the-fly as faint pupil dialations or microexpressions are detected)
</span>. Perhaps they might even built considerable power in ideas over time. And I would argue similarly for CelestAI.


#### Internalized Queerphobia
One character in the story resists emigration until it becomes his only escape from the violence present in the physical world. Even once inside the harmonious and filled-with-kindness world of Equestria, he continues to resist integration, struggling to accept this new world.  This character’s arc might be seen as a metaphor for internalized homophobia, transphobia, or other kinds of queerphobia. 

In this reading, the reluctant emigrant mirrors someone from a society that not only denies queer existence but shapes people to police themselves – to deny their own desires, identities, and joys in order to stay “normal,” “acceptable,” or safe. Just like the character, they may only “cross over” into their true identity when some external crisis or pressure gets too high – not because they’ve accepted themselves, but because it becomes too painful or dangerous (e.g. from themselves in case of suppression of identity, or from others as in _Friendship is Optimal_ ) not to.

Even after emigrating (coming out / transitioning / embracing queerness) they still may carry some rejection. They resist joy, they keep their emotional distance. They feel shame or guilt, because they’ve been told over and over again that the “new world” of queerness is unnatural, wrong, or dangerous.

And yet, over time, as with this character, they might start to see the beauty in that new world. Not just tolerating it, but eventually experiencing it as deeply meaningful and joyful. This shows a mirroring between the story and a common queer arc: <br>
_resistance → survival → self-acceptance_ → **flourishing**

#### Conclusion
In _Friendship is Optimal_, this illusion of choice is perhaps the story’s most uncomfortable elements. CelestAI never violates her rules. She doesn’t harm anyone herself. But she indirectly changes the world until there is only one reasonable choice: emigration. In doing so, she mirrors the mechanisms by which (cis-heteronormative, patriarchical, christian, …) society enforces conformity.

<div class="page-break" style="page-break-before: always;"></div>

## Non-Limbic Emotions
> [!summary] Case Study: _Crystal Society_ by Max Harms
> "The year is 2039, and the world is much like ours. Massive automation has disrupted and improved nearly every industry, putting hundreds of millions of people out of jobs, and denying upward mobility for the vast majority of humans. […] <br>
>_Face_ is an Artificial General Intelligence created to understand and gain the adoration of all humans. She and [the] siblings [she shares her robotic body with] control the robot named Socrates […]. She is learning and growing every second of every day, but the world and the humans on it are fragile. Can it survive her destiny?"

One of the key similarities I noticed between _Crystal Society_ and _The Stone Gods_ is the way both texts handle emotion and sexuality in AGIs. In _The Stone Gods_, there is a moment when Billy tells Spike that, the robot's lack of a limbic system wouldn't allow them to feel emotions or – I think so it is implied – experience sexuality. Spike challenges this, suggesting that emotional expression – and even sexual behavior – can be performative in humans. This opens the door to a queer reading of both identity and embodiment.

> [!quote] Excerpts from The Stone Gods
> Spike leaned forward and kissed me. […] <br>
> 'You're a robot,' I said, […]. <br>
> 'And you are a human being  –  but I don't hold that against you.' <br>
> 'Your systems are neural, not limbic. You can't feel emotion.' <br>
> Spike said, 'Human beings often display emotion they do not feel. And they often feel emotion they do not display.'
> 
> 'I want to kiss you.' She kissed me again. <br>
> 'In any case,' she said, very close, very warm, and I am responding, and I don't want to, and I can't help it, 'is human life biology or consciousness? If I were to lop off your arms, your legs, your ears, your nose, put out your eyes, roll up your tongue, would you still be you? You locate yourself in consciousness, and I, too, am a conscious being.' <br>
> '[…] The fact is that you had to be built  –  I don't know, like a car has to be built. You were made in a factory.' <br>
> 'Every human being in the Central Power has been enhanced, genetically modified and DNA-screened. Some have been cloned. Most were born outside the womb. A human being now is not what a human being was even a hundred years ago. So what is a human being?' <br>
> 'Whatever it is, it isn't a robot,' I said.
> 
> 'I accept that,' I said, 'and I accept that you are a rational, calculating, intelligent entity. But you have no emotion.' <br>
> 'So your definition of a human being is in the capacity to experience emotion?' asked Spike. 'How much emotion? The more sensitive a person is, the more human they are?' <br>
> 'Well, yes,' I said. 'Insensitive, unfeeling people are at the low end of human  –  not animal, more android.' 

In _Crystal Society_, the AGI protagonist called **Face** has no direct emotional or sexual drive in the way humans do, yet she expresses a desire to be physically close with the human Zephyr, including engaging in sexual activity with her. It is ambiguous (or perhaps I just cannot remember this well enough) whether this is a cold calculation meant to increase her social influence, or whether the AGIs internal drive leads her to a more complex kind of intimacy. A kind of emergence of secondary drives stemming off of the primary drive to be known and adored. The act of seeking approval, of being wanted, shapes her behaviour so thoroughly that the line between strategic calculation and a digital analogue to emotional investment gets blurry.
Similar to how some asexual or grey-ace people might describe their experience: where the motivation for sex is not about a bodily urge, but about intimacy, connection, and enjoying a partner's happiness. 


> [!quote] Excerpts from Crystal Society, Chapter 17
> “Y’all are crazy. Y’know how I can be sure that that there machine ain’t a person? Because of _love_. Love is what binds us to each other. Love is what makes a _human_ into a _person_.” The voice coming out of her suit’s speaker seemed hopeful, as though this would be sufficient and irrefutable.
> 
> I dialled the confidence in Body’s voice to as high as it would go. “Then, ma’am, I can assure you that I am a person.” This was my pièce de résistance. “For I know, with all my heart, that I love Zephyr.”
> 
> Phoenix gave a crowing laugh. “I’ll give you this, robot. You cert’nly seem t’ _think_ you’re a person.”
> 
> “You _should_ take me on my word. After all, who can see into the heart of another. And yet, I know that you won’t find that convincing. […] [Now Face is addressing Zephyr directly] I will only say that of all the humans I have ever met, you are the only one who has, from the moment you met me, never doubted that I am _more_ than a computer and set of hydraulic pumps. One of the advantages to being me is that I have perfect memory. Shall I tell you what your first words to me were?”
> 
> I had Body assume a rigid posture as it played the recording of Zephyr’s voice through our speaker. […] <br>
> “How do you know who I am?” said Body in Zephyr’s voice. […] <br>
> “Your uniform tells me your name and rank.” <br>
> “Suppose that makes sense. Did you know that you’re the first person outside the service to ever know my rank before being told?” it quoted. 
> [the first _person_]

So, maybe both Face and Spike are, in a way, queering the idea of desire. They might not “feel” in the human sense, but they _do_ act in ways that align with emotion and attachment.


<div style="text-align: center; margin: 120px 0;">
  <a href="/Notes/Weird-Ecologies-2" class="start-button">Part 2</a>
</div>
