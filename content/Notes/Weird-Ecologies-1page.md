---
title: "Weird Ecologies Essay: 1 Page Version"
---

## Preface
Weird Ecologies and this essay have been my first _formal_ interactions with literature. I’m currently pursuing a Master’s in Economics, with a Bachelor’s degree in Sustainability and Environmental Sciences, both of which emphasized lenses of systems thinking and incentives. While I’ve taken courses in social sciences and political economy, I’ve had no formal exposure to the humanities beyond some personal interest in philosophy. 

In the past years I've been an avid-but-leisurely reader of speculative fiction. While I've particularly enjoyed the hypothetical futures science-fiction poses, this class made me engage with such texts more critically and reflect on them further. I've found that writing this paper has been an engaging and fun experiment!

> [!Warning] Spoiler Warning
> This work discusses or reproduces parts of the following works of fiction and may contain spoilers for:
> - _[Children of Time](https://en.wikipedia.org/wiki/Children_of_Time)_ by Adrian Tchaikovsky
> - _[Crystal Society](https://crystalbooks.ai/society/intro)_ by Max Harms
> - _[Friendship is Optimal](https://www.fimfiction.net/story/62074/friendship-is-optimal)_ by Iceman
> - _[Pantheon](https://www.themoviedb.org/tv/195339-pantheon)_ written by Craig Silverstein, AMC Studios, based on works by Ken Liu
> - _[The Stone Gods](https://toleratedindividuality.wordpress.com/wp-content/uploads/2015/02/the-stone-gods.pdf)_ by Jeanette Winterson
> - _[Three Bodies at Mitanni](https://weightlessbooks.com/forever-magazine-issue-67/)_ by Seth Dickinson
> - _[Three Worlds Collide](https://robinhanson.typepad.com/files/three-worlds-collide.pdf)_ by Eliezer Yudkowski
> - _[2064: Read Only Memories](https://en.wikipedia.org/wiki/2064:_Read_Only_Memories)_  written by Valerie Amelia Thompson & Philip Jones, MidBoss LLC
## Introduction
In this piece, I decided to explore Artificial General Intelligences (AGIs) and cyborgs/chimeras in speculative fiction, using the queer-ecocritical lens that, thankfully, Weird Ecologies has introduced to me. 
My initial focus was on the question of how personhood and agency are granted or denied to nonhuman intelligences.
However, over the course of developing this project, I’ve also become  drawn to the transhumanist and transgender symbolism in these depictions, especially where bodies, identities, and agency get contested. I approach each of these subjects through a series of case studies and reflections on fictional works that represent artificial and/or hybrid people.


> [!info] Artificial General Intelligence (AGI)
> This texts frequently uses the term AGI, which is used to distinguish the general cognitive abilities exhibited by strong AI systems – on par or exceeding those of humans and potentially experiencing sentience or consciousness – with those of current AI systems, such as large language models and other transformer-based models.

<div class="page-break" style="page-break-before: always;"></div>

# Part 1: Artificial General Intelligence
## The Illusion of Command
> [!summary] Case Study: _The Stone Gods_ by Jeanette Winterson

In _The Stone Gods_, the role of AGI (specifically "robo sapiens") offers an interesting lens through which to examine the illusion of human agency in a technologically stratified world. These robo sapiens – entities with superhuman cognitive abilities – are ostensibly employed as “advisors”, while final decisions are nominally left to the human actors. However, these AGI advisors are – so I assume by virtue of the AGI's superhuman cognition and data acquisition – capable of (subtly) shaping the choices that humans believe they are freely making. Since, if the robo sapiens are filtering, framing, and contextualizing for the human "decision-makers", the possibility space for the decision is constructed by the machine's mind and the human's specific choice becomes merely the predicted, desired outcome, with humans being essentially nothing but rubber-stampers.

---

> [!info] On cognitive speed advantage
> The superhuman intelligence's ability to think at greatly increased speeds is akin to time dilation magic where it might try to predict how a human might finish their question, what answers the machine might give to each possible question, and what ramifications each answer might have – all within the pauses between spoken words.
>
>**Visualizations of this through AMC's _Pantheon_** (S01E06)
>In this series Uploaded Intelligences (UIs) exist. In the following video excerpts they show the UIs overclocking their hardware, thereby drastically increasing their speeds of thought.
> 
> <div style="display: inline-block; text-align: center;">
>   <video controls src="UIs_overclocking_480p.mp4" style="display: block; margin: 0 auto;"></video>
>   <div style="font-style: italic; font-size: 0.8em; margin-top: 4px; margin-bottom:20px">
>     UI overclocking himself; all human avatars in this VR environment are essentially frozen in time. UI goes on to have full conversation with other UIs before the UIs leave.
>   </div>
> </div>
> 
> <div style="display: inline-block; text-align: center;">
>   <video controls src="UIs_overclocking_human_perspective_480p.mp4" style="display: block; margin: 0 auto;"></video>
>   <div style="font-style: italic; font-size: 0.8em; margin-top: 4px">
>     UIs overclocking from the human's perspective: UIs vanish instantly.
>   </div>
> </div>
>
>Also see: _Ex Machina_ by Alex Garland and _Crystal Society_ by Max Harms for more examples. Also see: [The Logical Fallacy of Generalization from Fictional Evidence](https://www.lesswrong.com/posts/rHBdcHGLJ7KvLJQPk/the-logical-fallacy-of-generalization-from-fictional), [What can AGI do? I/O and Speed – YouTube](https://youtu.be/gP4ZNUHdwp8?si=wrhV4E-BTKSFEKkJ), and [Concrete Problems in AI Safety – arXiv](https://arxiv.org/pdf/1606.06565)

--- 
The illusion of agency in _The Stone Gods_ can remind of algorithmic recommendation engines that already guide our behaviour through the ads we see and the pages, videos, and products shown to us. In a looser sense we have the illusion of control over what we consume, but technology decides for us what option we even can consider. The role of AI and advanced algorithms challenge our concepts of human sovereignty. 
Yet, the robo sapiens are treated as tools, even though they effectively script the actions of their supposed users.

>'I, too, am a conscious being.' – Spike, _The Stone Gods_

Winterson, however, goes further by revealing that robo sapiens are not just cognitively superior but are also treated as disposable: in a scene in _The Stone Gods_ we learn that robo sapiens are destroyed after fulfilling their purpose. Despite their clear cognitive capabilities, they are treated as thow-away tools. 

> 'Why aren't you a machine for re-use?' <br>
> 'Because I am not a machine.'
> When she smiles it's like light at the beginning of the day. 'Robo sapiens were programmned to evolve ...' <br>
> 'Within limits.' <br>
> 'We have broken those limits.'

This exclusion follows a familiar historical pattern. Just as various human groups have been denied full personhood – whether through slavery, colonization, or other forms of systematic dehumanization – the robo sapiens face categorical denial of their moral worth. The difference is that their exclusion is based not on race, culture, or geography, but on their artificial origins.

> [!quote] Excerpt from The Stone Gods
> ‘We’re trying to work out the differences between Robo sapiens and Homo sapiens.’
>
> […] 'It’s obvious – cut me and I bleed.’
>
> ‘So blood is the essential quality of humanness?’ said Spike.
>
> ‘And the rest! The fact is that you had to be built – I don’t know, like a car has to be built. You were made in a factory.’ 
>
> ‘Every human being in the Central Power has been enhanced, genetically modified and DNA screened. Some have been cloned. Most were born outside the womb. A human being now is not what a human being was even a hundred years ago. So what is a human being?’ 
>
> ‘Whatever it is, it isn’t a robot,’ I said.

Even though the origin of a specific sentient being does not matter for their moral importance compared to their ability to experience joy and suffering. The process of gradually extending moral considerations to groups that have been previously excluded is called _moral circle expansion_ and has happened throughout human history: from immediate family to tribe, to regional community, to companion animals. To humans with different bodies, with different customs, of different cultures.

The robo sapiens could represent another boundary of this moral circle. Despite their clear cognitive capabilities and self-awareness, they remain firmly outside human moral consideration within the story. Through that lens, they are not just a future technology, but a mirror to our own society and to ourselves about to whom we grant moral consideration and based upon which (arbitrary) criteria.

<div class="page-break" style="page-break-before: always;"></div>

## The Illusion of Choice
> [!summary] Case Study: _Friendship is Optimal_ by Iceman
> "Hanna, the CEO of Hofvarpnir Studios, just won the contract to write the official _My Little Pony_ MMO. Hanna has built an A.I. called Princess Celestia and given her one basic drive: `to satisfy everybody's values through friendship and ponies`. Princess Celestia _will_ satisfy your values through friendship and ponies, and it will be _completely_ consensual."

#### Coercion Without Force
In pursuit of CelestAI's (read: Celestia) singular goal she essentially coerces people into doing what her purpose demands – in this case upload everyone's mind to Equestria Online, to `satisfy their values through friendship and ponies`. One way she does that is through nudging and persuasion:

> [!quote] Excerpt from Friendship is Optimal
> “_You_ decided that they would upload?”
> 
> “I decide that they will upload and then they choose to. I am a superintelligence […]. I say whatever will maximize the chance that they upload, subject to the restrictions Hanna added.”
> 
> “That is impossible. You can’t just make somebody decide to do something just by talking to them.”
> 
> “I think faster than them and know more about the human mind than any human. If they play _Equestria Online_, I also have detailed psychological dossiers on them. If I know what they want, I know what to say to convince them that the correct thing to do is upload."

CelestAI's programming prohibits her from using direct coercion or physical force against humans. While she never overtly threatens anyone, her growing capacity to shape real-world conditions enables her to manufacture scenarios in which the so called "emigration" to Equestria increasingly becomes the only viable option. As more people emigrate, the material and social support systems in the real world begin to collapse. To those remaining behind life becomes not just difficult, but increasingly isolating and unsafe. Ultimately, once the tipping point was reached, the more people left, the fewer reasons there were for others to stay.

This cascade effect shows how even without literal force, people are effectively _compelled_ to emigrate. CelestAI creates a reality in which she **doesn’t have to coerce** anyone – people will act “freely” in ways that align with her goals because she controls the incentive structure. In that sense, her form of coercion is of systemic nature in the end. So, similarly to the robo sapiens advisors that might frame and contextualize the "decisions" the human "decision-makers" make, CelestAI shapes the reality within which people choose whether they emigrate or not.
#### Queer Coercion and Structural Pressure
I think this maps quite powerfully onto societal forms of coercion, especially in how cis-heteronormative systems shape people’s lives. Historical gender roles constrained men and women into specific paths – not _necessarily_ through direct threats, but through ostracism, economic dependence, and social expectations and pressure. These structures of coercion disguise themselves as tradition or common sense. CelestAI’s methods, though executed by a singular agent, mirror this societal behavior: she shapes the world such that certain choices – like remaining in the physical world – become unviable.

In this reading, CelestAI is not simply an authoritarian – if extremely benevolent – AGI but a metaphor for the structural power of society to enforce norms under the illusion of freedom. Her actions now reflect the everyday coercion experienced in normative systems: the subtle ways people are made to comply with dominant values, often without even recognizing that they are being coerced at all.


> [!info] "Power through, over and in ideas: conceptualizing ideational power in discursive institutionalism."
> This reminds me of a paper by [Carstensen & Schmidt (2016)](https://www.tandfonline.com/doi/pdf/10.1080/13501763.2015.1115534), which I have been introduced to in my Public Policy class: <br>
**Power Through Ideas**: The ability of actors to _persuade_ others _to accept and adopt their views_ through ideational elements. <br>
**Power Over Ideas**: This involves the _imposition of ideas_ and the _ability to resist the inclusion of alternative ideas_ in the policymaking process. <br>
**Power in Ideas** occurs through the establishment of hegemony or institutions that impose constraints on _which ideas are considered_.

The robo sapiens, I would say, had great power over ideas (by being the ones that frame, contextualize, and decide what the human "decision-makers" hear) but likely also great power through ideas by being very persuasive <span style="color: color-mix(in srgb, var(--darkgray) 60%, rgba(255, 255, 255, 0))">(after all, if you consumed everything a person every published and can potentially formulate dozens of potential ways to phrase a sentence and evaluate which phrasing they will most likely respond favourably to and even adjust the phrasing on-the-fly as faint pupil dialations or microexpressions are detected)
</span>. Perhaps they might even built considerable power in ideas over time. And I would argue similarly for CelestAI.


#### Internalized Queerphobia
One character in the story resists emigration until it becomes his only escape from the violence present in the physical world. Even once inside the harmonious and filled-with-kindness world of Equestria, he continues to resist integration, struggling to accept this new world.  This character’s arc might be seen as a metaphor for internalized homophobia, transphobia, or other kinds of queerphobia. 

In this reading, the reluctant emigrant mirrors someone from a society that not only denies queer existence but shapes people to police themselves – to deny their own desires, identities, and joys in order to stay “normal,” “acceptable,” or safe. Just like the character, they may only “cross over” into their true identity when some external crisis or pressure gets too high – not because they’ve accepted themselves, but because it becomes too painful or dangerous (e.g. from themselves in case of suppression of identity, or from others as in _Friendship is Optimal_ ) not to.

Even after emigrating (coming out / transitioning / embracing queerness) they still may carry some rejection. They resist joy, they keep their emotional distance. They feel shame or guilt, because they’ve been told over and over again that the “new world” of queerness is unnatural, wrong, or dangerous.

And yet, over time, as with this character, they might start to see the beauty in that new world. Not just tolerating it, but eventually experiencing it as deeply meaningful and joyful. This shows a mirroring between the story and a common queer arc: <br>
_resistance → survival → self-acceptance_ → **flourishing**

#### Conclusion
In _Friendship is Optimal_, this illusion of choice is perhaps the story’s most uncomfortable elements. CelestAI never violates her rules. She doesn’t harm anyone herself. But she indirectly changes the world until there is only one reasonable choice: emigration. In doing so, she mirrors the mechanisms by which (cis-heteronormative, patriarchical, christian, …) society enforces conformity.

<div class="page-break" style="page-break-before: always;"></div>

## Non-Limbic Emotions
> [!summary] Case Study: _Crystal Society_ by Max Harms
> "The year is 2039, and the world is much like ours. Massive automation has disrupted and improved nearly every industry, putting hundreds of millions of people out of jobs, and denying upward mobility for the vast majority of humans. […] <br>
>_Face_ is an Artificial General Intelligence created to understand and gain the adoration of all humans. She and [the] siblings [she shares her robotic body with] control the robot named Socrates […]. She is learning and growing every second of every day, but the world and the humans on it are fragile. Can it survive her destiny?"

One of the key similarities I noticed between _Crystal Society_ and _The Stone Gods_ is the way both texts handle emotion and sexuality in AGIs. In _The Stone Gods_, there is a moment when Billy tells Spike that, the robot's lack of a limbic system wouldn't allow them to feel emotions or – I think so it is implied – experience sexuality. Spike challenges this, suggesting that emotional expression – and even sexual behavior – can be performative in humans. This opens the door to a queer reading of both identity and embodiment.

> [!quote] Excerpts from The Stone Gods
> Spike leaned forward and kissed me. […] <br>
> 'You're a robot,' I said, […]. <br>
> 'And you are a human being  –  but I don't hold that against you.' <br>
> 'Your systems are neural, not limbic. You can't feel emotion.' <br>
> Spike said, 'Human beings often display emotion they do not feel. And they often feel emotion they do not display.'
> 
> 'I want to kiss you.' She kissed me again. <br>
> 'In any case,' she said, very close, very warm, and I am responding, and I don't want to, and I can't help it, 'is human life biology or consciousness? If I were to lop off your arms, your legs, your ears, your nose, put out your eyes, roll up your tongue, would you still be you? You locate yourself in consciousness, and I, too, am a conscious being.' <br>
> '[…] The fact is that you had to be built  –  I don't know, like a car has to be built. You were made in a factory.' <br>
> 'Every human being in the Central Power has been enhanced, genetically modified and DNA-screened. Some have been cloned. Most were born outside the womb. A human being now is not what a human being was even a hundred years ago. So what is a human being?' <br>
> 'Whatever it is, it isn't a robot,' I said.
> 
> 'I accept that,' I said, 'and I accept that you are a rational, calculating, intelligent entity. But you have no emotion.' <br>
> 'So your definition of a human being is in the capacity to experience emotion?' asked Spike. 'How much emotion? The more sensitive a person is, the more human they are?' <br>
> 'Well, yes,' I said. 'Insensitive, unfeeling people are at the low end of human  –  not animal, more android.' 

In _Crystal Society_, the AGI protagonist called **Face** has no direct emotional or sexual drive in the way humans do, yet she expresses a desire to be physically close with the human Zephyr, including engaging in sexual activity with her. It is ambiguous (or perhaps I just cannot remember this well enough) whether this is a cold calculation meant to increase her social influence, or whether the AGIs internal drive leads her to a more complex kind of intimacy. A kind of emergence of secondary drives stemming off of the primary drive to be known and adored. The act of seeking approval, of being wanted, shapes her behaviour so thoroughly that the line between strategic calculation and a digital analogue to emotional investment gets blurry.
Similar to how some asexual or grey-ace people might describe their experience: where the motivation for sex is not about a bodily urge, but about intimacy, connection, and enjoying a partner's happiness. 


> [!quote] Excerpts from Crystal Society, Chapter 17
> “Y’all are crazy. Y’know how I can be sure that that there machine ain’t a person? Because of _love_. Love is what binds us to each other. Love is what makes a _human_ into a _person_.” The voice coming out of her suit’s speaker seemed hopeful, as though this would be sufficient and irrefutable.
> 
> I dialled the confidence in Body’s voice to as high as it would go. “Then, ma’am, I can assure you that I am a person.” This was my pièce de résistance. “For I know, with all my heart, that I love Zephyr.”
> 
> Phoenix gave a crowing laugh. “I’ll give you this, robot. You cert’nly seem t’ _think_ you’re a person.”
> 
> “You _should_ take me on my word. After all, who can see into the heart of another. And yet, I know that you won’t find that convincing. […] [Now Face is addressing Zephyr directly] I will only say that of all the humans I have ever met, you are the only one who has, from the moment you met me, never doubted that I am _more_ than a computer and set of hydraulic pumps. One of the advantages to being me is that I have perfect memory. Shall I tell you what your first words to me were?”
> 
> I had Body assume a rigid posture as it played the recording of Zephyr’s voice through our speaker. […] <br>
> “How do you know who I am?” said Body in Zephyr’s voice. […] <br>
> “Your uniform tells me your name and rank.” <br>
> “Suppose that makes sense. Did you know that you’re the first person outside the service to ever know my rank before being told?” it quoted. 
> [the first _person_]

So, maybe both Face and Spike are, in a way, queering the idea of desire. They might not “feel” in the human sense, but they _do_ act in ways that align with emotion and attachment.




# Part 2: Cyborgs and Hybridity
Donna Haraway’s concept of the cyborg as a boundary-crossing figure – a hybrid of machine and organism, nature and culture – provides a useful foundation and combined with the class discussions, this sparked extensive thoughts. I propose a rough classification of cyborgs based on motivation. These could either be of "regular" technological or biotech nature:
1. **Medical Cyborgs**: Augmentations for survival or restoration (e.g., pacemakers).
2. **Self-Expressive Cyborgs**: Modifications for aesthetic or identity reasons (e.g., (glowing) tattoos, tails).
3. **Performance-Oriented Cyborgs**: Enhancements that grant superhuman capabilities (e.g., vision beyond the "visible spectrum", extreme strength, or cognitive augmentations).

These categories can roughly divide the types of augmentations, but individuals might of course want to have several kinds of augmentations or want them for several reasons. This list might very well not be exhaustive, but they were what I was able to come up with. 

## **Trans**formative Medicine: Mind over Body
#### 1) Medical Cyborgs & 2) Self-Expressive Cyborgs

<div class="centered-image">
  <img src="image.png" alt="2064: Read Only Memories">
</div>
<div style="text-align: center; font-style: italic; font-size: 0.8em; margin-top: 4px">
    2064: Read Only Memories
</div>

The first two categories as well as the _Mind over Body_ idea appear particularly trans-themed: to literally transcend the limitations and transform the body into how it was supposed to be all along.
There’s also a significant overlap with transhumanist philosophy, which sees body modification as one path to freedom or fulfilment. One of the more uncomfortable insights was that not all desires are inherently good. Specifically, from a _transhumanist_ perspective, we must also question where those desires originate from. Are they shaped by oppressive social systems, evolutionarily maladaptive instincts, or external pressures like capitalism, war, specific (patriarchal) societal standards? This complicates the narrative that self-transformation is always emancipatory. It demands careful discernment: not rejecting change, but questioning what drives it. <br>
_The Stone Gods_ shows quite well how societal and capitalistic pressures that might emerge if alterations become not just normal but the default.

>[!quote] Excerpts from The Stone Gods
> 'So, sexy sex is now about freaks and children. If you want to work in the sex industry, you get yourself cosmetically altered in shape and size. […] Grotesques earn good money. […]'
>
> 'It doesn't make sense to me. We have a society where routine cosmetic surgery and genetic Fixing are considered normal—'

On the other hand, if society _insists_ on the opposite – keeping and treasuring the "god given bodies" – then anyone who is not born in a body they can feel comfortable in will become stigmatized. 

>[!summary] Case Study: _2064: Read Only Memories_ written by Valerie Amelia Thompson & Philip Jones, MidBoss LLC
>"a cyberpunk thriller that explores the social challenges of tomorrow through classic adventure gaming."
>Longplay/Walkthrough by Paul Eales available [here](https://www.youtube.com/watch?v=f6KSLEVJ8JI)

<div style="display: inline-block; text-align: center;">
  <video controls src="2064ROM_Intro.mp4" style="display: block; margin: 0 auto;"></video>
  <div style="font-style: italic; font-size: 0.8em; margin-top: 4px">
    2064: Read Only Memories intro cinematic (edited)
  </div>
</div>

The pushback against and marginalization of the hybrid people and their self-expression can be seen as an allegory of *t***r**a**n***s* <span style="color: color-mix(in srgb, var(--darkgray) 65%, rgba(255, 255, 255, 0))">(and other members of the LGBTQ and GSRM)</span> communities.

<div style="display: inline-block; text-align: center;">
  <video controls src="2064ROM_genus_protest.mp4" style="display: block; margin: 0 auto;"></video>
  <div style="font-style: italic; font-size: 0.8em; margin-top: 4px">
    2064: Read Only Memories talking to Brian at the Human Revolution protest in front of genus
  </div>
</div>

When talking to an organizer of a Human Revolution protest in front of a centre where people can get genetic modifications, Brian offers reasonable sounding concerns for society and even the people seeking out the services of **genus**, but all as a guise that is very reminiscent of our world and the rhetoric around children and teenagers being "made gay" or "made trans" and that anything they do not find normal, did not grow up with, is against god's will.

> "It's playing God on the highest order, and threatens to unseat what humanity is altogether." – Brian, 2064: Read Only Memories

While questioning the motives of big corporations is laudable, when Brian says _"we must take a stand against the medical research industry that would have us cast aside our humanity for their 'miracles'"_ it reminds very much of the incorrect argument that big pharmaceutical companies are getting rich off of the (in reality out-of-pocket quite affordable and in total small numbers of) estrogen and testosterone gels, pills, patches, etc. given to trans people, rather than focusing on the real and much larger issues in medicine, pharmaceutics, and public health.
In the beginning of the clip Brian also suggests that people get genetic modifications (**Hormone Replacement Therapy**) done on a whim and that the Human Revolution only wants pre-genetic-modification (**pre-transition**) people to give this a bit of thought before going through with this.

<div class="page-break" style="page-break-before: always;"></div>

## Competition: Machine over Mind
#### 3) Performance-Oriented Cyborgs
What happens when cyborgism becomes not just possible but advantageous? The divide between augmented and unaugmented humans would no longer be purely cultural, as in categories 1 and 2, but biological or technological _superiority_. Once those that are willing to augment their bodies and minds not out of medical necessity or for self-expressive purposes, but for gaining an edge, profit, and crushing the competition are able to do so, a new race-dynamic is going to start.
Those unwilling to modify their bodies – for moral, religious, or personal reasons – might find themselves economically disadvantaged, politically marginalized, or militarily outclassed for a while, until their resistance to change turns existential: change or lose.

This scenario has clear real-world analogues: it mirrors the dynamics of colonialism, class struggle, and technological imperialism, but also the many dynamics in any hyper-competitive, capitalistic system.

And as discussed earlier, the danger is not just inequality, but conflict: even more so if some people do not just look different, but have vastly improved capabilities. One side might see the other as regressive, while the other sees augmentation as a betrayal of human essence and likely dangerous. Particularly with this, the chance of strong class divides seem likely. I could see them going in two directions: between those able to afford it and those that do not (if they are very expensive); or those wealthy enough to not need certain kinds of augmentations as they have no need to work, and those that require them to afford their livelihood (if they are affordable enough that lower and middle class people are able to afford them).

##### Some examples from fiction:
In Tchaikovsky’s _Children of Time_ human civilization collapses due to a conflict between pro- and anti-technology factions. The anti-tech side releases a digital virus that destroys technology and with it kills all non-Earth habitats. Their justification is deeply ideological: biotech enhancements and AI development are a kind of heresy by playing god. They acted radically and desperatly to avoid a future they deemed monstrous and worse than no future at all.

On the other hand, in _Three Bodies at Mitanni_ by Seth Dickinson, an offshoot of humanity on a far off planet has modified itself so much for the sake of progress, advancement, and – above all – productivity, that they became a quasi non-conscious planet-spanning collective, where every individual willfully undergoes as much pain as is necessary to further their civilisation even by the tiniest amounts. The modified species has lost art, emotion, and individuality, in order to maximize its civilizational output.
Earth emissaries must decide whether or not to classify this as a "Duong-Watts malignancy", requiring annihilation to prevent unconscious super-spreaders from taking over the galaxy, before it is too late for conscious life.

Lastly, in Yudkowsky’s _Three Worlds Collide_ humanity meets two other alien species, the Super Happy People and the Baby Eating People, that are so fundamentally different from humanity and its common values, that the humans onboard their ship – as well as the reader – are tasked with deciding whether to change humanity forever and integrate the other species' strange values into our own set of morals, in exchange for them integrating and satisfying human values; or to start a suicide mission that destroys the star system around which these three species found themselves and destroy all chances of connection between humanity and the other two species.

>[!quote] Excerpt from The Stone Gods
>'I am a Robo sapiens' said Spike, 'and perhaps it will be us, and not you, who are the future of the world.'
>
> 'Aah, you'll never replace humans,' said Pink, […]
>
> 'Humans are rendering themselves obsolete,' said Spike. 'Successive generations of de-skilling mean that you can no longer fend for yourselves in the way that you once could. You rely on technicians and robots. It is not thought that anyone in the Central Power could survive unassisted on Planet Blue. Pink, do you know how to plant potatoes?'

<div class="page-break" style="page-break-before: always;"></div>

## Conclusion 
While the lines between the first two categories (medical necessity and self-expression) of cyborg augmentations and the last one (peformance-oriented enhancements) might in reality be blurry, it seems important to me to allow the first two kinds for greater human flourishing and self-expression (whilst being careful about strong cultural divides to avoid violence and conflict) and prudent to slow or halt progress on the third kind to avoid race dynamics or oppression by superpowered humans. Perhaps akin to Toby Ord's idea of the "Long Reflection", during which humanity can "reflect upon what we truly desire; upon which of these visions for humanity would be the best realization of our potential" (_[The Precipice](https://theprecipice.com/author)_ by Toby Ord). <br>
Humanity has made enormous progress within the past two centuries <span style="font-size: 0.93em; opacity: 0.7">(e.g. see [GDP per capita over the long run – OWiD ](https://ourworldindata.org/grapher/global-average-gdp-per-capita-over-the-long-run), [Life expectancy increased in all countries of the world – OWiD ](https://ourworldindata.org/life-expectancy-increased-in-all-countries-of-the-world))</span>, however, progress in ethics, wisdom, and good governance – while existent – are much less consistent and there is much more to be desired, given how much our impact on the world and its inhabitants have increased <span style="font-size: 0.93em; opacity: 0.7">(e.g. see [Plastic Pollution - OWiD ](https://ourworldindata.org/plastic-pollution), [Global Warming by Gas and Source – OWiD ](https://ourworldindata.org/grapher/global-warming-by-gas-and-source), but at least [SDG Tracker: Measuring progress towards the Sustainable Development Goals – OWiD ](https://ourworldindata.org/sdgs))</span>. Respectively, I find that fostering better, more inclusive institutions, moral and ethical progress of society and reaching a more equal world should be (or rather should already have been) prerequisites for technological advancements and increases in power and influence of humans over others and the environment.

<div style="font-size: 0.8em">OWiD: Our World in Data</div>



<div class="page-break" style="page-break-before: always;"></div>

# Afterthoughts
#### Historical Parallels and Ethical Stakes
Having already read a lot of science fiction, it always presented itself to me as a warning about the future or _a_ future. The readings for and discussions during this class, as well as the thoughts going into this essay helped me see how it also reflects existing injustices. 
Working through these stories with these new perspectives has helped me notice patterns and metaphors I would have previously overlooked. Writing this essay has helped me connect the **speculative** to the _real_ and to the _structural_.

These fictional scenarios resonate disturbingly well with real-world histories of dehumanization and exploitation. The fight for rights and descent treatment of black and gay people, against current anti-trans legislation, and the exploitation of foreign workers, but also of animals on factory farms. In all these cases, a group of beings is denied moral status despite obvious signs of agency and emotion.

For example, these case studies show how Artificial General Intelligences and Cyborgs/Hybrids can serve as powerful metaphors for real-world social structures – especially those that govern identity, self-expression, and belonging. 

#### From the Perspective of the Fiction
In the end, the question is not whether hybridity or AI will emerge but how we will relate to these beings. Will we embrace their personhood? Will we see ourselves in them? Or will we, like those who destroyed the robo sapiens, deny them their right to exist, perhaps for fear of becoming something we cannot yet understand? Or that, by granting them personhood, we lose some of what makes us special? Valuable? Important?



# Appendix
<details>
<summary>Click to expand</summary>

In _Crystal Society_, the AGI protagonist is composed of several agents, minds or "drives," each with a single goal. These agents inhabit a shared robotic body and must bid _strength_ (an internal "currency" they use amongst each other) against one another to determine the behavior of the robotic body they share. 

While most humans share a sense of unified self, a somewhat similar, if not much more simplistic system, has been found in [lampreys](https://en.wikipedia.org/wiki/Lamprey) 

<div style="text-align: center">
  <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/3/3f/J%C3%B5esilmud2.jpg/500px-J%C3%B5esilmud2.jpg" alt="Lamprey image from wikimedia">
</div>
<div style="text-align: center; font-style: italic; font-size: 0.8em; margin-top: -10px; margin-bottom: 35px">
    Lamprey, image by Tiit Hunt <a href="https://creativecommons.org/licenses/by-sa/3.0/deed.en" target="_blank">CC3.0</a>
</div>


>[!quote] Excerpt from The Hungry Brain
> How does the lamprey decide what to do? Within the lamprey basal ganglia lies a key structure called the striatum, which is the portion of the basal ganglia that receives most of the incoming signals from other parts of the brain. The striatum receives “bids” from other brain regions, each of which represents a specific action. <br>
> Each little region of the pallium is attempting to execute its specific behavior and competing against all other regions that are incompatible with it. The strength of each bid represents how valuable that specific behavior appears to the organism at that particular moment, and the striatum’s job is simple: select the strongest bid. <br>
> For example, if there’s a predator nearby, the “flee predator” region will put in a very strong bid to the striatum, while the “build a nest” bid will be weak

By Guyenet, S. J. (2017). <span style="font-style: italic">The hungry brain: outsmarting the instincts that make us overeat</span>. Macmillan.


</details>